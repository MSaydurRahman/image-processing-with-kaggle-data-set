{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image processing with kaggle data set part-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJA4cM7YZYwRJHcUizLNN7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSaydurRahman/image-processing-with-kaggle-data-set/blob/main/image_processing_with_kaggle_data_set_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oq00m6b6Thj"
      },
      "source": [
        "#Load libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib\n",
        "\n",
        "from collections import OrderedDict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbLdWKKfa5OD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be79593c-54c7-4a19-fe74-25182d08757c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QBOGP0cZu8u"
      },
      "source": [
        "#Path for training and testing directory\n",
        "train_path='/content/drive/My Drive/cse465/seg_train'\n",
        "test_path='/content/drive/My Drive/cse465/seg_test/seg_test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOA2WCthbKMV"
      },
      "source": [
        "#Transforms\n",
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzYQlqnfb4Ut"
      },
      "source": [
        "train_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=64, shuffle=True\n",
        ")\n",
        "test_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
        "    batch_size=32, shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMbX6SubbxSr"
      },
      "source": [
        "#categories\n",
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPMxGhWWbySx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b7dad42-829e-401f-8a85-1696fde8a545"
      },
      "source": [
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOhQURKqcncl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "20403068-41f3-4da7-9799-9b8659dfecb5"
      },
      "source": [
        "#Build and train network\n",
        "#transfer Learning\n",
        "model=models.vgg16(pretrained=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3dcd921dd1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Build and train network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#transfer Learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fb0iJnOc9Fa"
      },
      "source": [
        "#Freez pretrained model parameters to avoid backpropagating through them\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False  \n",
        " \n",
        "from collections import OrderedDict\n",
        "#build custom classifier\n",
        "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088,5000 )),\n",
        "                                        ('relu', nn.ReLU()),\n",
        "                                        ('drop', nn.Dropout(p=0.5)),\n",
        "                                        ('fc2', nn.Linear(5000, 6)),\n",
        "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
        "\n",
        "model.classifier = classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZSlPXzHnJrg"
      },
      "source": [
        "#Model training and saving best model\n",
        "\n",
        "\n",
        "def train_classifier():\n",
        "  with active_session():\n",
        "    \n",
        "    steps = 0\n",
        "    print_every = 40\n",
        "    model.to('cuda')\n",
        "\n",
        "    for e in range(epoch):\n",
        "    #Evaluation and training on training dataset\n",
        "        train()\n",
        "        train_accuracy=0.0\n",
        "        train_loss=0.0\n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "            outputs=model(images)\n",
        "            loss=loss_function(outputs,labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        \n",
        "            train_loss+= loss.cpu().data*images.size(0)\n",
        "            _,prediction=torch.max(outputs.data,1)\n",
        "        \n",
        "            train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "        \n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "    \n",
        "    \n",
        "    # Evaluation on testing dataset\n",
        "    model.eval()\n",
        "    \n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    \n",
        "    \n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "    \n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}