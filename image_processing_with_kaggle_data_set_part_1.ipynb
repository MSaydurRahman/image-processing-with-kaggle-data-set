{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image processing with kaggle data set part-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSaydurRahman/image-processing-with-kaggle-data-set/blob/main/image_processing_with_kaggle_data_set_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h28AA6INltY"
      },
      "source": [
        "#Load libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MekaT9E5N2p6"
      },
      "source": [
        "#checking for device\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRpDuhA9N6Lw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "746cf833-a6e6-48e2-b92c-b08f93232607"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ns4kW3N6PK"
      },
      "source": [
        "#Transforms\n",
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78hzq2aPOBkG"
      },
      "source": [
        "#Dataloader\n",
        "\n",
        "#Path for training and testing directory\n",
        "train_path='/content/drive/My Drive/cse465/seg_train'\n",
        "test_path='/content/drive/My Drive/cse465/seg_test/seg_test'\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=32, shuffle=True\n",
        ")\n",
        "test_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
        "    batch_size=32, shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrJoc7EAOXCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c09b6d5-260b-4b1b-d4ac-2978d8116cc7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiZNE_tNOBv0"
      },
      "source": [
        "#categories\n",
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DghGb1n9O1fm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2f06b16-d7a4-414d-e83e-2f455830fab5"
      },
      "source": [
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNQuxgAoO1ig"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=6):\n",
        "        super(ConvNet,self).__init__()\n",
        "        \n",
        "        #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "        \n",
        "        #Input shape= (256,3,150,150)\n",
        "        \n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (256,12,150,150)\n",
        "        \n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (256,12,75,75)\n",
        "        \n",
        "        \n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (256,20,75,75)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (256,32,75,75)\n",
        "        \n",
        "        \n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Feed forwad function\n",
        "        \n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "            \n",
        "        output=self.pool(output)\n",
        "            \n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "            \n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "            \n",
        "            \n",
        "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "            \n",
        "        output=output.view(-1,32*75*75)\n",
        "            \n",
        "            \n",
        "        output=self.fc(output)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd1IBIkUPwUT"
      },
      "source": [
        "model=ConvNet(num_classes=6).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub5WidFsO1vr"
      },
      "source": [
        "#Optmizer and loss function\n",
        "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DixwClM2O1rR"
      },
      "source": [
        "num_epochs=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHXBBidLO1qY"
      },
      "source": [
        "#calculating the size of training and testing images\n",
        "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncvAkMqZO1pn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11d893c2-3d82-4128-ea4c-909521f7becd"
      },
      "source": [
        "print(train_count,test_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14034 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySO4iSPvPe-m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "d322bef5-ee3b-4f31-a2de-60035966eecb"
      },
      "source": [
        "#Model training and saving best model\n",
        "\n",
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        \n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "        \n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "    \n",
        "    \n",
        "    # Evaluation on testing dataset\n",
        "    model.eval()\n",
        "    \n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    \n",
        "    \n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "    \n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss: tensor(4.7786) Train Accuracy: 0.5844377939290295 Test Accuracy: 0.6356666666666667\n",
            "Epoch: 1 Train Loss: tensor(0.7690) Train Accuracy: 0.7503919053726664 Test Accuracy: 0.7246666666666667\n",
            "Epoch: 2 Train Loss: tensor(0.4972) Train Accuracy: 0.8324782670656976 Test Accuracy: 0.7453333333333333\n",
            "Epoch: 3 Train Loss: tensor(0.3623) Train Accuracy: 0.8827846658116004 Test Accuracy: 0.7496666666666667\n",
            "Epoch: 4 Train Loss: tensor(0.2911) Train Accuracy: 0.9032350007125552 Test Accuracy: 0.7103333333333334\n",
            "Epoch: 5 Train Loss: tensor(0.2388) Train Accuracy: 0.9248254239703577 Test Accuracy: 0.76\n",
            "Epoch: 6 Train Loss: tensor(0.2018) Train Accuracy: 0.936938862761864 Test Accuracy: 0.7526666666666667\n",
            "Epoch: 7 Train Loss: tensor(0.1808) Train Accuracy: 0.9458458030497363 Test Accuracy: 0.723\n",
            "Epoch: 8 Train Loss: tensor(0.1883) Train Accuracy: 0.940715405443922 Test Accuracy: 0.7563333333333333\n",
            "Epoch: 9 Train Loss: tensor(0.1676) Train Accuracy: 0.9499073678210062 Test Accuracy: 0.7626666666666667\n",
            "Epoch: 10 Train Loss: tensor(0.1522) Train Accuracy: 0.9554652985606384 Test Accuracy: 0.7136666666666667\n",
            "Epoch: 11 Train Loss: tensor(0.1626) Train Accuracy: 0.9527575887131252 Test Accuracy: 0.753\n",
            "Epoch: 12 Train Loss: tensor(0.1522) Train Accuracy: 0.9553227875160325 Test Accuracy: 0.7373333333333333\n",
            "Epoch: 13 Train Loss: tensor(0.1241) Train Accuracy: 0.9661536269060852 Test Accuracy: 0.7183333333333334\n",
            "Epoch: 14 Train Loss: tensor(0.1254) Train Accuracy: 0.9618070400456036 Test Accuracy: 0.7476666666666667\n",
            "Epoch: 15 Train Loss: tensor(0.1161) Train Accuracy: 0.9655123272053584 Test Accuracy: 0.75\n",
            "Epoch: 16 Train Loss: tensor(0.1027) Train Accuracy: 0.9740629898817158 Test Accuracy: 0.764\n",
            "Epoch: 17 Train Loss: tensor(0.0839) Train Accuracy: 0.9757018668946843 Test Accuracy: 0.7526666666666667\n",
            "Epoch: 18 Train Loss: tensor(0.0945) Train Accuracy: 0.973421690180989 Test Accuracy: 0.765\n",
            "Epoch: 19 Train Loss: tensor(0.0897) Train Accuracy: 0.9764144221177141 Test Accuracy: 0.7583333333333333\n",
            "Epoch: 20 Train Loss: tensor(0.0902) Train Accuracy: 0.9759156334615933 Test Accuracy: 0.737\n",
            "Epoch: 21 Train Loss: tensor(0.0990) Train Accuracy: 0.9733504346586861 Test Accuracy: 0.7523333333333333\n",
            "Epoch: 22 Train Loss: tensor(0.0937) Train Accuracy: 0.9747755451047456 Test Accuracy: 0.7643333333333333\n",
            "Epoch: 23 Train Loss: tensor(0.0800) Train Accuracy: 0.9765569331623201 Test Accuracy: 0.7593333333333333\n",
            "Epoch: 24 Train Loss: tensor(0.0868) Train Accuracy: 0.9764144221177141 Test Accuracy: 0.753\n",
            "Epoch: 25 Train Loss: tensor(0.0749) Train Accuracy: 0.9809747755451047 Test Accuracy: 0.7626666666666667\n",
            "Epoch: 26 Train Loss: tensor(0.0707) Train Accuracy: 0.9821861194242554 Test Accuracy: 0.759\n",
            "Epoch: 27 Train Loss: tensor(0.0639) Train Accuracy: 0.9851788513609805 Test Accuracy: 0.7536666666666667\n",
            "Epoch: 28 Train Loss: tensor(0.0684) Train Accuracy: 0.9826136525580732 Test Accuracy: 0.7763333333333333\n",
            "Epoch: 29 Train Loss: tensor(0.0749) Train Accuracy: 0.983397463303406 Test Accuracy: 0.7523333333333333\n",
            "Epoch: 30 Train Loss: tensor(0.0602) Train Accuracy: 0.9855351289724954 Test Accuracy: 0.7556666666666667\n",
            "Epoch: 31 Train Loss: tensor(0.0604) Train Accuracy: 0.9852501068832834 Test Accuracy: 0.7513333333333333\n",
            "Epoch: 32 Train Loss: tensor(0.0759) Train Accuracy: 0.9823998859911643 Test Accuracy: 0.7576666666666667\n",
            "Epoch: 33 Train Loss: tensor(0.0590) Train Accuracy: 0.9876015391192817 Test Accuracy: 0.754\n",
            "Epoch: 34 Train Loss: tensor(0.0572) Train Accuracy: 0.9882428388200085 Test Accuracy: 0.7616666666666667\n",
            "Epoch: 35 Train Loss: tensor(0.0593) Train Accuracy: 0.9848225737494656 Test Accuracy: 0.7683333333333333\n",
            "Epoch: 36 Train Loss: tensor(0.0767) Train Accuracy: 0.9851075958386775 Test Accuracy: 0.7623333333333333\n",
            "Epoch: 37 Train Loss: tensor(0.0617) Train Accuracy: 0.986675217329343 Test Accuracy: 0.776\n",
            "Epoch: 38 Train Loss: tensor(0.0502) Train Accuracy: 0.9895966937437651 Test Accuracy: 0.7683333333333333\n",
            "Epoch: 39 Train Loss: tensor(0.0544) Train Accuracy: 0.9854638734501924 Test Accuracy: 0.752\n",
            "Epoch: 40 Train Loss: tensor(0.0759) Train Accuracy: 0.9848938292717686 Test Accuracy: 0.7683333333333333\n",
            "Epoch: 41 Train Loss: tensor(0.0550) Train Accuracy: 0.9885278609092205 Test Accuracy: 0.77\n",
            "Epoch: 42 Train Loss: tensor(0.0535) Train Accuracy: 0.9888128829984324 Test Accuracy: 0.753\n",
            "Epoch: 43 Train Loss: tensor(0.0569) Train Accuracy: 0.9864614507624341 Test Accuracy: 0.7586666666666667\n",
            "Epoch: 44 Train Loss: tensor(0.0697) Train Accuracy: 0.9836824853926179 Test Accuracy: 0.769\n",
            "Epoch: 45 Train Loss: tensor(0.0468) Train Accuracy: 0.9903805044890979 Test Accuracy: 0.7743333333333333\n",
            "Epoch: 46 Train Loss: tensor(0.0619) Train Accuracy: 0.9883853498646145 Test Accuracy: 0.7663333333333333\n",
            "Epoch: 47 Train Loss: tensor(0.0587) Train Accuracy: 0.990309248966795 Test Accuracy: 0.7746666666666666\n",
            "Epoch: 48 Train Loss: tensor(0.0604) Train Accuracy: 0.9885278609092205 Test Accuracy: 0.7773333333333333\n",
            "Epoch: 49 Train Loss: tensor(0.0488) Train Accuracy: 0.9895966937437651 Test Accuracy: 0.7736666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}